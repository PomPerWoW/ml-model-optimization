{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import pickle\n",
                "from app.util.timer import Timer\n",
                "from app.util.Differ import MatrixDiffer\n",
                "from main import YoloRuntimeTest\n",
                "import time\n",
                "from threading import Thread"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "CPU input"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "args_pytorch = {\n",
                "    \"weights\": \"./app/weights/yolov9c.pt\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\",\n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_onnx = {\n",
                "    \"weights\": \"./app/weights/yolov9c-quantize.onnx\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_onnx_runtime_model = {\n",
                "    \"weights\": \"./app/weights/yolov9c-quantize.onnx\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"onnxruntime_model\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_openvino = {\n",
                "    \"weights\": \"./app/weights/yolov9c_openvino_model\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_openvino_model = {\n",
                "    \"weights\": \"./app/weights/yolov9c_openvino_model/yolov9c.xml\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"openvino_model\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Initilize YOLO runtime test and Timer classes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "yolo_runtime_test = YoloRuntimeTest()\n",
                "timer = Timer()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "yolo_runtime_test.export_onnx_quantize()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cpu_pytorch_ultralytics_image = yolo_runtime_test.ultralytics_run_image(args_pytorch)\n",
                "print(cpu_pytorch_ultralytics_image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cpu_openvino_ultralytics_image = yolo_runtime_test.ultralytics_run_image(args_openvino)\n",
                "print(cpu_openvino_ultralytics_image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cpu_openvino_model_image = yolo_runtime_test.openvino_run_image(args_openvino_model)\n",
                "print(cpu_openvino_model_image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[INFO] Inference Image\n",
                        "Loading app\\weights\\yolov9c-quantize.onnx for ONNX Runtime inference...\n",
                        "\n",
                        "[[[     11.497      15.618      23.312 ...      543.81      569.74      603.58]\n",
                        "  [     22.046      21.142      21.218 ...      613.57      623.57      619.28]\n",
                        "  [     30.757      37.472      30.971 ...      405.02      423.79      386.74]\n",
                        "  ...\n",
                        "  [ 3.5763e-07  1.4901e-07  1.4901e-07 ...   2.563e-06  2.6226e-06  3.1292e-06]\n",
                        "  [ 3.2783e-07  2.9802e-07  2.6822e-07 ...  2.7716e-06  3.0994e-06  2.8014e-06]\n",
                        "  [ 1.7881e-07  1.1921e-07  2.0862e-07 ...  2.2352e-06  2.8908e-06  2.5034e-06]]]\n",
                        "0: 640x640 2 cars, 1 truck, 3 traffic lights, 184.5ms\n",
                        "Speed: 7.0ms preprocess, 184.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
                        "Elapsed time: 1.7478 seconds\n",
                        "([['traffic light', 0.8753820657730103, 513, 364, 564, 529], ['traffic light', 0.8653980493545532, 35, 342, 101, 514], ['car', 0.7800920605659485, 802, 1144, 898, 1232], ['car', 0.7567036151885986, 970, 1123, 1067, 1234], ['traffic light', 0.6532491445541382, 956, 431, 1046, 544], ['truck', 0.6365572214126587, 424, 1098, 710, 1368]], 1.7477844000000005, 184.5245361328125)\n"
                    ]
                }
            ],
            "source": [
                "cpu_onnx_ultralytics_image = yolo_runtime_test.ultralytics_run_image(args_onnx)\n",
                "print(cpu_onnx_ultralytics_image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[INFO] Inference Image\n",
                        "[[[     11.497      15.618      23.312 ...      543.81      569.74      603.58]\n",
                        "  [     22.046      21.142      21.218 ...      613.57      623.57      619.28]\n",
                        "  [     30.757      37.472      30.971 ...      405.02      423.79      386.74]\n",
                        "  ...\n",
                        "  [ 3.5763e-07  1.4901e-07  1.4901e-07 ...   2.563e-06  2.6226e-06  3.1292e-06]\n",
                        "  [ 3.2783e-07  2.9802e-07  2.6822e-07 ...  2.7716e-06  3.0994e-06  2.8014e-06]\n",
                        "  [ 1.7881e-07  1.1921e-07  2.0862e-07 ...  2.2352e-06  2.8908e-06  2.5034e-06]]]\n",
                        "Elapsed time: 0.1786 seconds\n",
                        "([['traffic light', 0.8753820657730103, 513, 464, 564, 587], ['traffic light', 0.8653980493545532, 35, 448, 101, 577], ['car', 0.7800920605659485, 802, 1050, 898, 1115], ['car', 0.7567036151885986, 970, 1034, 1066, 1117], ['traffic light', 0.6532491445541382, 956, 515, 1045, 599], ['truck', 0.6365572214126587, 424, 1016, 709, 1217]], 0.17863199999999857, 0.0)\n"
                    ]
                }
            ],
            "source": [
                "cpu_onnx_runtime_model_image = yolo_runtime_test.onnxruntime_run_image(args_onnx_runtime_model)\n",
                "print(cpu_onnx_runtime_model_image)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Difference CPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.set_option('display.expand_frame_repr', False)\n",
                "\n",
                "with open('pytorch_ultralytics_outputs.pkl', 'rb') as f:\n",
                "    pytorch_ultralytics_outputs = pickle.load(f)\n",
                "with open('openvino_ultralytics_outputs.pkl', 'rb') as f:\n",
                "    openvino_ultralytics_outputs = pickle.load(f)\n",
                "with open('onnx_ultralytics_outputs.pkl', 'rb') as f:\n",
                "    onnx_ultralytics_outputs = pickle.load(f)\n",
                "with open('onnx_model_outputs.pkl', 'rb') as f:\n",
                "    onnx_model_outputs = pickle.load(f)\n",
                "\n",
                "def generate_difference_df(output1, output2):\n",
                "    differ = MatrixDiffer(output1, output2)\n",
                "    result = differ.find_difference()\n",
                "    return result\n",
                "\n",
                "print(generate_difference_df(pytorch_ultralytics_outputs, openvino_ultralytics_outputs))\n",
                "print(generate_difference_df(pytorch_ultralytics_outputs, onnx_ultralytics_outputs))\n",
                "print(generate_difference_df(pytorch_ultralytics_outputs, onnx_model_outputs))\n",
                "print(generate_difference_df(onnx_ultralytics_outputs, openvino_ultralytics_outputs))\n",
                "print(generate_difference_df(onnx_ultralytics_outputs, onnx_model_outputs))\n",
                "print(generate_difference_df(onnx_model_outputs, openvino_ultralytics_outputs))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Average CPU Time (10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time = []\n",
                "ultralytics_inference_time = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_inference_with_args(inference_func, args):\n",
                "    def wrapper():\n",
                "        return inference_func(args)\n",
                "    return wrapper\n",
                "\n",
                "def collect_execution_times(run_inference_func, args, iterations=100):\n",
                "    execution_times = []\n",
                "    for i in range(iterations):\n",
                "        args[\"source\"] = f\"./app/assets/sample_image_{i}.jpg\"\n",
                "        wrapper_func = run_inference_with_args(run_inference_func, args)\n",
                "        result = wrapper_func()\n",
                "        execution_times.append(result[1] * 1000)\n",
                "        ultralytics_inference_time.append(result[2])\n",
                "    return execution_times\n",
                "\n",
                "args_pytorch = {\n",
                "    \"weights\": \"./app/weights/yolov9c.pt\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\",\n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_onnx = {\n",
                "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_onnx_runtime_model = {\n",
                "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"onnxruntime_model\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_openvino = {\n",
                "    \"weights\": \"./app/weights/yolov9c_openvino_model\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_openvino_model = {\n",
                "    \"weights\": \"./app/weights/yolov9c_openvino_model/yolov9c.xml\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"openvino_model\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_pytorch))\n",
                "# result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_openvino))\n",
                "# result_time.append(collect_execution_times(yolo_runtime_test.openvino_run_image, args_openvino_model))\n",
                "# result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_onnx))\n",
                "# result_time.append(collect_execution_times(yolo_runtime_test.onnxruntime_run_image, args_onnx_runtime_model))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_openvino))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_onnx))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time.append(collect_execution_times(yolo_runtime_test.openvino_run_image, args_openvino_model))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time.append(collect_execution_times(yolo_runtime_test.onnxruntime_run_image, args_onnx_runtime_model))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time = np.array(result_time)\n",
                "df = pd.DataFrame(np.transpose(result_time), \n",
                "                  columns=[\"pytorch+ultralytics time cpu (ms)\",\n",
                "                           \"openvino+ultralytics time cpu (ms)\",\n",
                "                           \"onnxâ€‹+ultralytics time cpu (ms)\",\n",
                "                           \"openvino model time cpu (ms)\", \n",
                "                           \"onnx runtime model time cpu (ms)\"])\n",
                "df.describe(percentiles=[.9, .95])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ultralytics_inference_time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def split_list_into_arrays(input_list):\n",
                "    list1 = input_list[:100]\n",
                "    list2 = input_list[100:200]\n",
                "    list3 = input_list[200:300]\n",
                "    \n",
                "    return list1, list2, list3\n",
                "\n",
                "array1, array2, array3 = split_list_into_arrays(ultralytics_inference_time)\n",
                "infer_timer_list = [array1, array2, array3]\n",
                "\n",
                "print(infer_timer_list)\n",
                "\n",
                "infer_timer_list = np.array(infer_timer_list)\n",
                "df_infer = pd.DataFrame(np.transpose(infer_timer_list), columns=[\"pytorch+ultralytics built-in profiler time cpu (ms)\", \"openvino+ultralytics built-in profiler time cpu (ms)\", \"onnx+ultralytics built-in profiler time cpu (ms)\"])\n",
                "df_infer.describe(percentiles=[.9, .95])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save CPU result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('./app/saved_pkl/cpu_df.pkl', 'wb') as f:\n",
                "    pickle.dump(df, f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('./app/saved_pkl/cpu_infer_df.pkl', 'wb') as f:\n",
                "    pickle.dump(df_infer, f)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "yolov9",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}

{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import pickle\n",
                "from app.util.timer import Timer\n",
                "from app.util.Differ import MatrixDiffer\n",
                "from main import YoloRuntimeTest\n",
                "import time\n",
                "from threading import Thread"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "CPU input"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "args_pytorch = {\n",
                "    \"weights\": \"./app/weights/yolov9c.pt\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\",\n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_onnx = {\n",
                "    \"weights\": \"./app/weights/yolov9c-quantize.onnx\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_onnx_runtime_model = {\n",
                "    \"weights\": \"./app/weights/yolov9c-quantize.onnx\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"onnxruntime_model\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_openvino = {\n",
                "    \"weights\": \"./app/weights/yolov9c_openvino_model\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_openvino_model = {\n",
                "    \"weights\": \"./app/weights/yolov9c_openvino_model/yolov9c.xml\", \n",
                "    \"source\": \"./app/assets/sample_image_1.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"openvino_model\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Initilize YOLO runtime test and Timer classes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "yolo_runtime_test = YoloRuntimeTest()\n",
                "timer = Timer()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "yolo_runtime_test.export_onnx_quantize()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[INFO] Inference Image\n",
                        "\n",
                        "\n",
                        "tensor([[[7.8437e+00, 1.4626e+01, 2.6670e+01,  ..., 5.4648e+02, 5.7641e+02, 6.0165e+02],\n",
                        "         [1.2257e+01, 1.6441e+01, 2.1075e+01,  ..., 6.1850e+02, 6.2164e+02, 6.2050e+02],\n",
                        "         [2.2509e+01, 3.5542e+01, 4.1705e+01,  ..., 3.9399e+02, 4.0604e+02, 3.8676e+02],\n",
                        "         ...,\n",
                        "         [4.8817e-07, 3.7641e-07, 3.3249e-07,  ..., 2.7438e-06, 2.8189e-06, 2.9413e-06],\n",
                        "         [2.8484e-07, 2.9415e-07, 2.9807e-07,  ..., 3.3928e-06, 3.3278e-06, 2.8392e-06],\n",
                        "         [2.9322e-07, 2.7852e-07, 3.9879e-07,  ..., 2.4420e-06, 2.9020e-06, 2.4951e-06]]])\n",
                        "0: 640x640 4 cars, 1 truck, 3 traffic lights, 398.6ms\n",
                        "0: 640x640 4 cars, 1 truck, 3 traffic lights, 398.6ms\n",
                        "Speed: 6.0ms preprocess, 398.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
                        "Speed: 6.0ms preprocess, 398.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
                        "Elapsed time: 1.8482 seconds\n",
                        "([['traffic light', 0.8275656700134277, 36, 342, 103, 517], ['traffic light', 0.8228888511657715, 513, 363, 565, 529], ['car', 0.8164669871330261, 802, 1144, 899, 1232], ['car', 0.8075482249259949, 970, 1124, 1066, 1235], ['traffic light', 0.6712052226066589, 955, 431, 1046, 545], ['car', 0.6568469405174255, 924, 1145, 958, 1185], ['truck', 0.6473277807235718, 424, 1098, 709, 1367], ['car', 0.6341714262962341, 381, 1155, 443, 1228]], 1.8482371999999998, 398.5772132873535)\n"
                    ]
                }
            ],
            "source": [
                "cpu_pytorch_ultralytics_image = yolo_runtime_test.ultralytics_run_image(args_pytorch)\n",
                "print(cpu_pytorch_ultralytics_image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[INFO] Inference Image\n",
                        "Loading app\\weights\\yolov9c_openvino_model for OpenVINO inference...\n",
                        "Loading app\\weights\\yolov9c_openvino_model for OpenVINO inference...\n",
                        "Using OpenVINO LATENCY mode for batch=1 inference...\n",
                        "Using OpenVINO LATENCY mode for batch=1 inference...\n",
                        "\n",
                        "\n",
                        "[[[     7.8437      14.626       26.67 ...      546.48      576.41      601.65]\n",
                        "  [     12.257      16.441      21.075 ...       618.5      621.64       620.5]\n",
                        "  [     22.509      35.542      41.705 ...      393.99      406.04      386.76]\n",
                        "  ...\n",
                        "  [ 4.8818e-07  3.7641e-07  3.3249e-07 ...  2.7438e-06  2.8189e-06  2.9413e-06]\n",
                        "  [ 2.8484e-07  2.9415e-07  2.9807e-07 ...  3.3928e-06  3.3278e-06  2.8393e-06]\n",
                        "  [ 2.9322e-07  2.7852e-07   3.988e-07 ...   2.442e-06   2.902e-06  2.4951e-06]]]\n",
                        "0: 640x640 4 cars, 1 truck, 3 traffic lights, 103.2ms\n",
                        "0: 640x640 4 cars, 1 truck, 3 traffic lights, 103.2ms\n",
                        "Speed: 5.0ms preprocess, 103.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
                        "Speed: 5.0ms preprocess, 103.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
                        "Elapsed time: 2.0059 seconds\n",
                        "([['traffic light', 0.827565610408783, 36, 342, 103, 517], ['traffic light', 0.8228884935379028, 513, 363, 565, 529], ['car', 0.8164668083190918, 802, 1144, 899, 1232], ['car', 0.8075480461120605, 970, 1124, 1066, 1235], ['traffic light', 0.6712057590484619, 955, 431, 1046, 545], ['car', 0.6568467617034912, 924, 1145, 958, 1185], ['truck', 0.6473270654678345, 424, 1098, 709, 1367], ['car', 0.6341710090637207, 381, 1155, 443, 1228]], 2.005864399999993, 103.24525833129883)\n"
                    ]
                }
            ],
            "source": [
                "cpu_openvino_ultralytics_image = yolo_runtime_test.ultralytics_run_image(args_openvino)\n",
                "print(cpu_openvino_ultralytics_image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "Check 'm_impl->m_outputs.size() == 1' failed at src\\core\\src\\preprocess\\pre_post_process.cpp:125:\nPrePostProcessor::output() - Model must have exactly one output, got 4\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cpu_openvino_model_image \u001b[38;5;241m=\u001b[39m \u001b[43myolo_runtime_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopenvino_run_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs_openvino_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(cpu_openvino_model_image)\n",
                        "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\pomper\\Internship\\ml-model-optimization\\main.py:188\u001b[0m, in \u001b[0;36mYoloRuntimeTest.openvino_run_image\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopenvino_run_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, args):\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a video using the Openvino model.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_openvino_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_on_image(model, args)\n",
                        "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\pomper\\Internship\\ml-model-optimization\\main.py:72\u001b[0m, in \u001b[0;36mYoloRuntimeTest._initialize_openvino_model\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(weights_path), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms no weight file with name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(classes_path), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms no classes file with name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 72\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLOv9Openvino\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconf_threshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miou_threshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
                        "File \u001b[1;32m~\\OneDrive\\Desktop\\pomper\\Internship\\ml-model-optimization\\app\\yolov9_openvino.py:30\u001b[0m, in \u001b[0;36mYOLOv9Openvino.__init__\u001b[1;34m(self, xml_model_path, classes, conf, nms)\u001b[0m\n\u001b[0;32m     28\u001b[0m ppp\u001b[38;5;241m.\u001b[39minput()\u001b[38;5;241m.\u001b[39mmodel()\u001b[38;5;241m.\u001b[39mset_layout(Layout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCHW\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#  Specify output results format\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43mppp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtensor()\u001b[38;5;241m.\u001b[39mset_element_type(Type\u001b[38;5;241m.\u001b[39mf32)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Embed above steps in the graph\u001b[39;00m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m ppp\u001b[38;5;241m.\u001b[39mbuild()\n",
                        "\u001b[1;31mRuntimeError\u001b[0m: Check 'm_impl->m_outputs.size() == 1' failed at src\\core\\src\\preprocess\\pre_post_process.cpp:125:\nPrePostProcessor::output() - Model must have exactly one output, got 4\n"
                    ]
                }
            ],
            "source": [
                "cpu_openvino_model_image = yolo_runtime_test.openvino_run_image(args_openvino_model)\n",
                "print(cpu_openvino_model_image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[INFO] Inference Image\n",
                        "Loading app\\weights\\yolov9c-quantize.onnx for ONNX Runtime inference...\n",
                        "\n",
                        "[[[     11.497      15.618      23.312 ...      543.81      569.74      603.58]\n",
                        "  [     22.046      21.142      21.218 ...      613.57      623.57      619.28]\n",
                        "  [     30.757      37.472      30.971 ...      405.02      423.79      386.74]\n",
                        "  ...\n",
                        "  [ 3.5763e-07  1.4901e-07  1.4901e-07 ...   2.563e-06  2.6226e-06  3.1292e-06]\n",
                        "  [ 3.2783e-07  2.9802e-07  2.6822e-07 ...  2.7716e-06  3.0994e-06  2.8014e-06]\n",
                        "  [ 1.7881e-07  1.1921e-07  2.0862e-07 ...  2.2352e-06  2.8908e-06  2.5034e-06]]]\n",
                        "0: 640x640 2 cars, 1 truck, 3 traffic lights, 171.3ms\n",
                        "Speed: 6.5ms preprocess, 171.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
                        "Elapsed time: 1.7082 seconds\n",
                        "([['traffic light', 0.8753820657730103, 513, 364, 564, 529], ['traffic light', 0.8653980493545532, 35, 342, 101, 514], ['car', 0.7800920605659485, 802, 1144, 898, 1232], ['car', 0.7567036151885986, 970, 1123, 1067, 1234], ['traffic light', 0.6532491445541382, 956, 431, 1046, 544], ['truck', 0.6365572214126587, 424, 1098, 710, 1368]], 1.7082325000000012, 171.3411808013916)\n"
                    ]
                }
            ],
            "source": [
                "cpu_onnx_ultralytics_image = yolo_runtime_test.ultralytics_run_image(args_onnx)\n",
                "print(cpu_onnx_ultralytics_image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[INFO] Inference Image\n",
                        "[[[     11.497      15.618      23.312 ...      543.81      569.74      603.58]\n",
                        "  [     22.046      21.142      21.218 ...      613.57      623.57      619.28]\n",
                        "  [     30.757      37.472      30.971 ...      405.02      423.79      386.74]\n",
                        "  ...\n",
                        "  [ 3.5763e-07  1.4901e-07  1.4901e-07 ...   2.563e-06  2.6226e-06  3.1292e-06]\n",
                        "  [ 3.2783e-07  2.9802e-07  2.6822e-07 ...  2.7716e-06  3.0994e-06  2.8014e-06]\n",
                        "  [ 1.7881e-07  1.1921e-07  2.0862e-07 ...  2.2352e-06  2.8908e-06  2.5034e-06]]]\n",
                        "Elapsed time: 0.1957 seconds\n",
                        "([['traffic light', 0.8753820657730103, 513, 464, 564, 587], ['traffic light', 0.8653980493545532, 35, 448, 101, 577], ['car', 0.7800920605659485, 802, 1050, 898, 1115], ['car', 0.7567036151885986, 970, 1034, 1066, 1117], ['traffic light', 0.6532491445541382, 956, 515, 1045, 599], ['truck', 0.6365572214126587, 424, 1016, 709, 1217]], 0.19568900000000156, 0.0)\n"
                    ]
                }
            ],
            "source": [
                "cpu_onnx_runtime_model_image = yolo_runtime_test.onnxruntime_run_image(args_onnx_runtime_model)\n",
                "print(cpu_onnx_runtime_model_image)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Difference CPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.set_option('display.expand_frame_repr', False)\n",
                "\n",
                "with open('pytorch_ultralytics_outputs.pkl', 'rb') as f:\n",
                "    pytorch_ultralytics_outputs = pickle.load(f)\n",
                "with open('openvino_ultralytics_outputs.pkl', 'rb') as f:\n",
                "    openvino_ultralytics_outputs = pickle.load(f)\n",
                "with open('onnx_ultralytics_outputs.pkl', 'rb') as f:\n",
                "    onnx_ultralytics_outputs = pickle.load(f)\n",
                "with open('onnx_model_outputs.pkl', 'rb') as f:\n",
                "    onnx_model_outputs = pickle.load(f)\n",
                "\n",
                "def generate_difference_df(output1, output2):\n",
                "    differ = MatrixDiffer(output1, output2)\n",
                "    result = differ.find_difference()\n",
                "    return result\n",
                "\n",
                "print(generate_difference_df(pytorch_ultralytics_outputs, openvino_ultralytics_outputs))\n",
                "print(generate_difference_df(pytorch_ultralytics_outputs, onnx_ultralytics_outputs))\n",
                "print(generate_difference_df(pytorch_ultralytics_outputs, onnx_model_outputs))\n",
                "print(generate_difference_df(onnx_ultralytics_outputs, openvino_ultralytics_outputs))\n",
                "print(generate_difference_df(onnx_ultralytics_outputs, onnx_model_outputs))\n",
                "print(generate_difference_df(onnx_model_outputs, openvino_ultralytics_outputs))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Average CPU Time (10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time = []\n",
                "ultralytics_inference_time = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_inference_with_args(inference_func, args):\n",
                "    def wrapper():\n",
                "        return inference_func(args)\n",
                "    return wrapper\n",
                "\n",
                "def collect_execution_times(run_inference_func, args, iterations=100):\n",
                "    execution_times = []\n",
                "    for i in range(iterations):\n",
                "        args[\"source\"] = f\"./app/assets/sample_image_{i}.jpg\"\n",
                "        wrapper_func = run_inference_with_args(run_inference_func, args)\n",
                "        result = wrapper_func()\n",
                "        execution_times.append(result[1] * 1000)\n",
                "        ultralytics_inference_time.append(result[2])\n",
                "    return execution_times\n",
                "\n",
                "args_pytorch = {\n",
                "    \"weights\": \"./app/weights/yolov9c.pt\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\",\n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_onnx = {\n",
                "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_onnx_runtime_model = {\n",
                "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"onnxruntime_model\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_openvino = {\n",
                "    \"weights\": \"./app/weights/yolov9c_openvino_model\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"ultralytics\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "args_openvino_model = {\n",
                "    \"weights\": \"./app/weights/yolov9c_openvino_model/yolov9c.xml\", \n",
                "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
                "    \"classes\": \"./app/weights/metadata.yaml\",\n",
                "    \"inference_type\": \"openvino_model\",\n",
                "    \"type\": \"image\", \n",
                "    \"show\": False,\n",
                "    \"conf_threshold\": 0.6, \n",
                "    \"iou_threshold\": 0.6, \n",
                "    \"device\": \"cpu\"\n",
                "}\n",
                "\n",
                "result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_pytorch))\n",
                "# result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_openvino))\n",
                "# result_time.append(collect_execution_times(yolo_runtime_test.openvino_run_image, args_openvino_model))\n",
                "# result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_onnx))\n",
                "# result_time.append(collect_execution_times(yolo_runtime_test.onnxruntime_run_image, args_onnx_runtime_model))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_openvino))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_onnx))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time.append(collect_execution_times(yolo_runtime_test.openvino_run_image, args_openvino_model))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time.append(collect_execution_times(yolo_runtime_test.onnxruntime_run_image, args_onnx_runtime_model))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_time = np.array(result_time)\n",
                "df = pd.DataFrame(np.transpose(result_time), \n",
                "                  columns=[\"pytorch+ultralytics time cpu (ms)\",\n",
                "                           \"openvino+ultralytics time cpu (ms)\",\n",
                "                           \"onnxâ€‹+ultralytics time cpu (ms)\",\n",
                "                           \"openvino model time cpu (ms)\", \n",
                "                           \"onnx runtime model time cpu (ms)\"])\n",
                "df.describe(percentiles=[.9, .95])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ultralytics_inference_time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def split_list_into_arrays(input_list):\n",
                "    list1 = input_list[:100]\n",
                "    list2 = input_list[100:200]\n",
                "    list3 = input_list[200:300]\n",
                "    \n",
                "    return list1, list2, list3\n",
                "\n",
                "array1, array2, array3 = split_list_into_arrays(ultralytics_inference_time)\n",
                "infer_timer_list = [array1, array2, array3]\n",
                "\n",
                "print(infer_timer_list)\n",
                "\n",
                "infer_timer_list = np.array(infer_timer_list)\n",
                "df_infer = pd.DataFrame(np.transpose(infer_timer_list), columns=[\"pytorch+ultralytics built-in profiler time cpu (ms)\", \"openvino+ultralytics built-in profiler time cpu (ms)\", \"onnx+ultralytics built-in profiler time cpu (ms)\"])\n",
                "df_infer.describe(percentiles=[.9, .95])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save CPU result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('./app/saved_pkl/cpu_df.pkl', 'wb') as f:\n",
                "    pickle.dump(df, f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('./app/saved_pkl/cpu_infer_df.pkl', 'wb') as f:\n",
                "    pickle.dump(df_infer, f)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "yolov9",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}

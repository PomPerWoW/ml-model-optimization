{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from app.util.timer import Timer\n",
    "from app.util.Differ import Differ\n",
    "from main import YoloRuntimeTest\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check CUDA available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pytorch = {\n",
    "    \"weights\": \"./app/weights/yolov9c.pt\", \n",
    "    \"source\": \"./app/assets/sample_image_3.jpg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\", \n",
    "    \"type\": \"image\",\n",
    "    \"show\": False, \n",
    "    \"conf_threshold\": 0.6, \n",
    "    \"iou_threshold\": 0.45, \n",
    "    \"device\": \"cuda:0\"\n",
    "}\n",
    "\n",
    "args_onnx = {\n",
    "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
    "    \"source\": \"./app/assets/sample_image_3.jpg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\",\n",
    "    \"type\": \"image\", \n",
    "    \"show\": False, \n",
    "    \"conf_threshold\": 0.6, \n",
    "    \"iou_threshold\": 0.45, \n",
    "    \"device\": \"cuda:0\"\n",
    "}\n",
    "\n",
    "args_openvino = {\n",
    "    \"weights\": \"./app/weights/yolov9c_openvino_model\", \n",
    "    \"source\": \"./app/assets/sample_image_3.jpg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\",\n",
    "    \"type\": \"image\", \n",
    "    \"show\": False, \n",
    "    \"conf_threshold\": 0.6, \n",
    "    \"iou_threshold\": 0.45, \n",
    "    \"device\": \"cuda:0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilize YOLO runtime test class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_runtime_test = YoloRuntimeTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initialize Model\n",
      "[INFO] Inference Image\n",
      "\n",
      "\n",
      "session run: 0.008196900000001506\n",
      "image 1/1 c:\\Users\\User\\OneDrive\\Desktop\\pomper\\Internship\\yolov9\\app\\assets\\sample_image_3.jpg: 480x640 1 person, 4 cars, 6 traffic lights, 8.0ms\n",
      "image 1/1 c:\\Users\\User\\OneDrive\\Desktop\\pomper\\Internship\\yolov9\\app\\assets\\sample_image_3.jpg: 480x640 1 person, 4 cars, 6 traffic lights, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Elapsed time: 0.2345 seconds\n",
      "Class: car, Confidence: 0.93, Box: [1, 2018, 664, 2355]\n",
      "Class: car, Confidence: 0.91, Box: [815, 2097, 1315, 2295]\n",
      "Class: traffic light, Confidence: 0.82, Box: [1346, 1263, 1408, 1428]\n",
      "Class: traffic light, Confidence: 0.82, Box: [1907, 1279, 1966, 1447]\n",
      "Class: person, Confidence: 0.82, Box: [1487, 2043, 1569, 2324]\n",
      "Class: traffic light, Confidence: 0.81, Box: [1162, 1202, 1228, 1366]\n",
      "Class: traffic light, Confidence: 0.79, Box: [3014, 773, 3155, 1041]\n",
      "Class: traffic light, Confidence: 0.76, Box: [629, 1187, 698, 1353]\n",
      "Class: car, Confidence: 0.71, Box: [1799, 2216, 1914, 2290]\n",
      "Class: traffic light, Confidence: 0.66, Box: [411, 1513, 488, 1640]\n",
      "Class: car, Confidence: 0.64, Box: [2998, 2193, 3468, 2359]\n",
      "([['car', 0.9271767735481262, 1, 2018, 664, 2355], ['car', 0.9052380323410034, 815, 2097, 1315, 2295], ['traffic light', 0.823891818523407, 1346, 1263, 1408, 1428], ['traffic light', 0.8213894963264465, 1907, 1279, 1966, 1447], ['person', 0.8199774026870728, 1487, 2043, 1569, 2324], ['traffic light', 0.8113959431648254, 1162, 1202, 1228, 1366], ['traffic light', 0.7884622812271118, 3014, 773, 3155, 1041], ['traffic light', 0.7594167590141296, 629, 1187, 698, 1353], ['car', 0.713955819606781, 1799, 2216, 1914, 2290], ['traffic light', 0.6624890565872192, 411, 1513, 488, 1640], ['car', 0.637826681137085, 2998, 2193, 3468, 2359]], 0.23454499999999712)\n"
     ]
    }
   ],
   "source": [
    "gpu_pytorch_image = yolo_runtime_test.ultralytics_run_image(args_pytorch)\n",
    "print(gpu_pytorch_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_openvino_image = yolo_runtime_test.ultralytics_run_image(args_openvino)\n",
    "print(gpu_openvino_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initialize Model\n",
      "[INFO] Inference Image\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "session run: 0.01912209999999881\n",
      "image 1/1 c:\\Users\\User\\OneDrive\\Desktop\\pomper\\Internship\\yolov9\\app\\assets\\sample_image_3.jpg: 640x640 1 person, 4 cars, 6 traffic lights, 22.7ms\n",
      "Speed: 38.6ms preprocess, 22.7ms inference, 628.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Elapsed time: 9.8181 seconds\n",
      "Class: car, Confidence: 0.93, Box: [1, 2018, 663, 2354]\n",
      "Class: car, Confidence: 0.91, Box: [815, 2097, 1315, 2295]\n",
      "Class: person, Confidence: 0.82, Box: [1487, 2043, 1569, 2323]\n",
      "Class: traffic light, Confidence: 0.82, Box: [1346, 1262, 1409, 1428]\n",
      "Class: traffic light, Confidence: 0.81, Box: [1907, 1279, 1967, 1447]\n",
      "Class: traffic light, Confidence: 0.81, Box: [1162, 1202, 1228, 1366]\n",
      "Class: traffic light, Confidence: 0.80, Box: [3014, 773, 3155, 1041]\n",
      "Class: traffic light, Confidence: 0.76, Box: [629, 1187, 698, 1353]\n",
      "Class: car, Confidence: 0.71, Box: [1799, 2216, 1914, 2290]\n",
      "Class: traffic light, Confidence: 0.67, Box: [411, 1513, 488, 1638]\n",
      "Class: car, Confidence: 0.64, Box: [2997, 2193, 3468, 2360]\n",
      "([['car', 0.9287940859794617, 1, 2018, 663, 2354], ['car', 0.907780110836029, 815, 2097, 1315, 2295], ['person', 0.8232042193412781, 1487, 2043, 1569, 2323], ['traffic light', 0.8191820979118347, 1346, 1262, 1409, 1428], ['traffic light', 0.8144267201423645, 1907, 1279, 1967, 1447], ['traffic light', 0.8084321618080139, 1162, 1202, 1228, 1366], ['traffic light', 0.8003469109535217, 3014, 773, 3155, 1041], ['traffic light', 0.7567164301872253, 629, 1187, 698, 1353], ['car', 0.7071438431739807, 1799, 2216, 1914, 2290], ['traffic light', 0.6712276935577393, 411, 1513, 488, 1638], ['car', 0.6351366639137268, 2997, 2193, 3468, 2360]], 9.818105699999998)\n"
     ]
    }
   ],
   "source": [
    "gpu_onnx_image = yolo_runtime_test.ultralytics_run_image(args_onnx)\n",
    "print(gpu_onnx_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_onnx_runtime_image = yolo_runtime_test.onnxruntime_run_image(args_onnx)\n",
    "print(gpu_onnx_runtime_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "def generate_difference_df(image1, image2, label):\n",
    "    differ = Differ(np.array(image1), np.array(image2))\n",
    "    result = differ.find_difference()\n",
    "    return pd.DataFrame(result, columns=[label, \"gpu conf_diff\", \"gpu box_diff (px)\"])\n",
    "\n",
    "df_pt_openvino = generate_difference_df(gpu_pytorch_image[0], gpu_openvino_image[0], \"pt vs openvino+ultralytics\")\n",
    "df_pt_onnx = generate_difference_df(gpu_pytorch_image[0], gpu_onnx_image[0], \"pt vs onnx+ultralytics\")\n",
    "df_pt_onnxruntime = generate_difference_df(gpu_pytorch_image[0], gpu_onnx_runtime_image[0], \"pt vs onnxruntime\")\n",
    "\n",
    "df_combined = pd.concat([df_pt_openvino, df_pt_onnx, df_pt_onnxruntime], axis=1)\n",
    "\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average GPU Time (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_execution_times(run_inference_func, iterations=10):\n",
    "    execution_times = []\n",
    "    for _ in range(iterations):\n",
    "        execution_time = run_inference_func()\n",
    "        execution_times.append(execution_time[1] * 100)\n",
    "    return execution_times\n",
    "\n",
    "pytorch_func = partial(yolo_runtime_test.ultralytics_run_image, args=args_pytorch)\n",
    "openvino_func = partial(yolo_runtime_test.ultralytics_run_image, args=args_openvino)\n",
    "onnx_func = partial(yolo_runtime_test.ultralytics_run_image, args=args_onnx)\n",
    "onnx_runtime_func = partial(yolo_runtime_test.onnxruntime_run_image, args=args_onnx)\n",
    "\n",
    "result_time.append(collect_execution_times(pytorch_func))\n",
    "result_time.append(collect_execution_times(openvino_func))\n",
    "result_time.append(collect_execution_times(onnx_func))\n",
    "result_time.append(collect_execution_times(onnx_runtime_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_time = np.array(result_time)\n",
    "df = pd.DataFrame(np.transpose(result_time), \n",
    "                  columns=[\"pytorch time gpu (ms)\",\n",
    "                           \"openvino+ultralytics time gpu (ms)\",\n",
    "                           \"onnx​+ultralytics time gpu (ms)\", \n",
    "                           \"onnx runtime time gpu (ms)\"])\n",
    "df.describe(percentiles=[.9, .95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save GPU result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./app/saved_pkl/gpu_df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from app.util.timer import Timer\n",
    "from app.util.Differ import Differ\n",
    "from main import YoloRuntimeTest\n",
    "from functools import partial\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check CUDA available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pytorch = {\n",
    "    \"weights\": \"./app/weights/yolov9c.pt\", \n",
    "    \"source\": \"./app/assets/sample_image_2.jpg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\",\n",
    "    \"inference_type\": \"ultralytics\",\n",
    "    \"type\": \"image\",\n",
    "    \"show\": False,\n",
    "    \"conf_threshold\": 0.6, \n",
    "    \"iou_threshold\": 0.6, \n",
    "    \"device\": \"cuda:0\"\n",
    "}\n",
    "\n",
    "args_onnx = {\n",
    "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
    "    \"source\": \"./app/assets/sample_image_2.jpg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\",\n",
    "    \"inference_type\": \"ultralytics\",\n",
    "    \"type\": \"image\", \n",
    "    \"show\": False,\n",
    "    \"conf_threshold\": 0.6, \n",
    "    \"iou_threshold\": 0.6, \n",
    "    \"device\": \"cuda:0\"\n",
    "}\n",
    "\n",
    "args_onnx_runtime_model = {\n",
    "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
    "    \"source\": \"./app/assets/sample_image_2.jpg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\",\n",
    "    \"inference_type\": \"onnxruntime_model\",\n",
    "    \"type\": \"image\", \n",
    "    \"show\": False,\n",
    "    \"conf_threshold\": 0.6, \n",
    "    \"iou_threshold\": 0.6, \n",
    "    \"device\": \"cuda:0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilize YOLO runtime test class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_runtime_test = YoloRuntimeTest()\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "gpu_pytorch_ultralytics_image = yolo_runtime_test.ultralytics_run_image(args_pytorch)\n",
    "timer.stop()\n",
    "print(f'Execution function time: {timer.elapsed_time} s')\n",
    "print(gpu_pytorch_ultralytics_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "gpu_onnx_ultralytics_image = yolo_runtime_test.ultralytics_run_image(args_onnx)\n",
    "timer.stop()\n",
    "print(f'Execution function time: {timer.elapsed_time} s')\n",
    "print(gpu_onnx_ultralytics_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "gpu_onnx_runtime_model_image = yolo_runtime_test.onnxruntime_run_image(args_onnx_runtime_model)\n",
    "timer.stop()\n",
    "print(f'Execution function time: {timer.elapsed_time} s')\n",
    "print(gpu_onnx_runtime_model_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "def generate_difference_df(image1, image2, label):\n",
    "    differ = Differ(np.array(image1), np.array(image2))\n",
    "    result = differ.find_difference()\n",
    "    return pd.DataFrame(result, columns=[label, \"gpu conf_diff\", \"gpu box_diff (px)\"])\n",
    "\n",
    "df_pt_onnx_ultralytics = generate_difference_df(gpu_pytorch_ultralytics_image[0], gpu_onnx_ultralytics_image[0], \"pt vs onnx+ultralytics\")\n",
    "df_pt_onnxruntime_model = generate_difference_df(gpu_pytorch_ultralytics_image[0], gpu_onnx_runtime_model_image[0], \"pt vs onnxruntime model\")\n",
    "\n",
    "df_combined = pd.concat([df_pt_onnx_ultralytics, df_pt_onnxruntime_model], axis=1)\n",
    "\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average GPU Time (100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_time = []\n",
    "ultralytics_inference_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0: 448x640 1 person, 1 bicycle, 3 cars, 3 trucks, 98.1ms\n",
      "0: 448x640 1 person, 1 bicycle, 3 cars, 3 trucks, 98.1ms\n",
      "Speed: 4.0ms preprocess, 98.1ms inference, 60.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Speed: 4.0ms preprocess, 98.1ms inference, 60.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "\n",
      "0: 480x640 6 cars, 2 traffic lights, 95.8ms\n",
      "0: 480x640 6 cars, 2 traffic lights, 95.8ms\n",
      "Speed: 1.5ms preprocess, 95.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 1.5ms preprocess, 95.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 5 cars, 6 traffic lights, 9.0ms\n",
      "0: 480x640 5 cars, 6 traffic lights, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 4 cars, 6 traffic lights, 11.5ms\n",
      "0: 480x640 1 person, 4 cars, 6 traffic lights, 11.5ms\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 5 cars, 6 traffic lights, 6.6ms\n",
      "0: 480x640 5 cars, 6 traffic lights, 6.6ms\n",
      "Speed: 2.5ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 2.5ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 1 motorcycle, 1 umbrella, 91.6ms\n",
      "0: 384x640 1 person, 4 cars, 1 motorcycle, 1 umbrella, 91.6ms\n",
      "Speed: 1.0ms preprocess, 91.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Speed: 1.0ms preprocess, 91.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "\n",
      "0: 480x640 3 cars, 6.5ms\n",
      "0: 480x640 3 cars, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 car, 2 traffic lights, 7.0ms\n",
      "0: 480x640 1 car, 2 traffic lights, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 6 cars, 7.5ms\n",
      "0: 480x640 6 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 (no detections), 6.1ms\n",
      "0: 480x640 (no detections), 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 7.0ms\n",
      "0: 640x640 6 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 1 car, 1 truck, 6.0ms\n",
      "0: 640x640 1 person, 1 car, 1 truck, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 7 cars, 7.5ms\n",
      "0: 640x640 7 cars, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 bicycle, 4 cars, 6.5ms\n",
      "0: 640x640 1 bicycle, 4 cars, 6.5ms\n",
      "Speed: 2.6ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.6ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 2 trucks, 9.5ms\n",
      "0: 640x640 2 cars, 2 trucks, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 5 cars, 7.2ms\n",
      "0: 640x640 1 person, 5 cars, 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 8.0ms\n",
      "0: 640x640 3 cars, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 6.4ms\n",
      "0: 640x640 4 cars, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 3 persons, 2 bananas, 6.1ms\n",
      "0: 640x640 3 persons, 2 bananas, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 8 cars, 6.0ms\n",
      "0: 640x640 8 cars, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 7.5ms\n",
      "0: 640x640 1 car, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 1 truck, 6.5ms\n",
      "0: 640x640 1 car, 1 truck, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 6.7ms\n",
      "0: 640x640 1 car, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 7.5ms\n",
      "0: 640x640 4 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 1 bus, 6.5ms\n",
      "0: 640x640 2 cars, 1 bus, 6.5ms\n",
      "Speed: 1.1ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.1ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 1 fire hydrant, 7.0ms\n",
      "0: 640x640 6 cars, 1 fire hydrant, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 5.5ms\n",
      "0: 640x640 1 car, 5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 1 traffic light, 6.2ms\n",
      "0: 640x640 2 cars, 1 traffic light, 6.2ms\n",
      "Speed: 2.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 9 cars, 6.1ms\n",
      "0: 640x640 9 cars, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 7.5ms\n",
      "0: 640x640 1 car, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 6 cars, 6.5ms\n",
      "0: 640x640 1 person, 6 cars, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 7.0ms\n",
      "0: 640x640 4 cars, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 6.5ms\n",
      "0: 640x640 2 cars, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 6.9ms\n",
      "0: 640x640 1 car, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 6.5ms\n",
      "0: 640x640 1 car, 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 10.0ms\n",
      "0: 640x640 2 cars, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 8.6ms\n",
      "0: 640x640 (no detections), 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 10.1ms\n",
      "0: 640x640 5 cars, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 11.0ms\n",
      "0: 640x640 1 car, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 11.3ms\n",
      "0: 640x640 5 cars, 11.3ms\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 11.7ms\n",
      "0: 640x640 1 car, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 13.5ms\n",
      "0: 640x640 1 car, 13.5ms\n",
      "Speed: 0.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 0.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 31.9ms\n",
      "0: 640x640 1 car, 31.9ms\n",
      "Speed: 1.0ms preprocess, 31.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 31.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 26.5ms\n",
      "0: 640x640 5 cars, 26.5ms\n",
      "Speed: 2.1ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.1ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 21.8ms\n",
      "0: 640x640 5 cars, 21.8ms\n",
      "Speed: 1.0ms preprocess, 21.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 1 truck, 19.6ms\n",
      "0: 640x640 6 cars, 1 truck, 19.6ms\n",
      "Speed: 2.0ms preprocess, 19.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 19.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 18.1ms\n",
      "0: 640x640 4 cars, 18.1ms\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 8 cars, 24.8ms\n",
      "0: 640x640 1 person, 8 cars, 24.8ms\n",
      "Speed: 2.0ms preprocess, 24.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 24.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 24.0ms\n",
      "0: 640x640 1 car, 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 24.5ms\n",
      "0: 640x640 (no detections), 24.5ms\n",
      "Speed: 2.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 1 truck, 17.0ms\n",
      "0: 640x640 6 cars, 1 truck, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 21.3ms\n",
      "0: 640x640 1 car, 21.3ms\n",
      "Speed: 1.5ms preprocess, 21.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 21.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 16.5ms\n",
      "0: 640x640 (no detections), 16.5ms\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 23.9ms\n",
      "0: 640x640 2 cars, 23.9ms\n",
      "Speed: 2.0ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 17.5ms\n",
      "0: 640x640 (no detections), 17.5ms\n",
      "Speed: 2.5ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 persons, 17.0ms\n",
      "0: 640x640 2 persons, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 16.0ms\n",
      "0: 640x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 27.1ms\n",
      "0: 640x640 1 car, 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 17.8ms\n",
      "0: 640x640 3 cars, 17.8ms\n",
      "Speed: 1.5ms preprocess, 17.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 17.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 21.6ms\n",
      "0: 640x640 6 cars, 21.6ms\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 21.2ms\n",
      "0: 640x640 2 cars, 21.2ms\n",
      "Speed: 1.0ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 20.0ms\n",
      "0: 640x640 5 cars, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 6.0ms\n",
      "0: 640x640 2 cars, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 1 car, 1 bus, 2 traffic lights, 6.5ms\n",
      "0: 640x640 1 person, 1 car, 1 bus, 2 traffic lights, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 8 cars, 6.0ms\n",
      "0: 640x640 8 cars, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 1 truck, 6.7ms\n",
      "0: 640x640 4 cars, 1 truck, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 persons, 4 cars, 6.0ms\n",
      "0: 640x640 2 persons, 4 cars, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 9 cars, 1 stop sign, 5.4ms\n",
      "0: 640x640 9 cars, 1 stop sign, 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 1 car, 10.6ms\n",
      "0: 640x640 1 person, 1 car, 10.6ms\n",
      "Speed: 1.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 10.1ms\n",
      "0: 640x640 5 cars, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 8 cars, 11.6ms\n",
      "0: 640x640 8 cars, 11.6ms\n",
      "Speed: 1.0ms preprocess, 11.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 11.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 12.9ms\n",
      "0: 640x640 1 car, 12.9ms\n",
      "Speed: 0.0ms preprocess, 12.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 0.0ms preprocess, 12.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 12.0ms\n",
      "0: 640x640 1 car, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 7 cars, 1 stop sign, 12.4ms\n",
      "0: 640x640 7 cars, 1 stop sign, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 23.1ms\n",
      "0: 640x640 (no detections), 23.1ms\n",
      "Speed: 2.0ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 20.0ms\n",
      "0: 640x640 (no detections), 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 suitcase, 6.5ms\n",
      "0: 640x640 1 suitcase, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 6.0ms\n",
      "0: 640x640 1 car, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 6.5ms\n",
      "0: 640x640 3 cars, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 persons, 1 fire hydrant, 7.5ms\n",
      "0: 640x640 2 persons, 1 fire hydrant, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 6.4ms\n",
      "0: 640x640 1 car, 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 7.5ms\n",
      "0: 640x640 5 cars, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 1 truck, 6.0ms\n",
      "0: 640x640 4 cars, 1 truck, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 6.0ms\n",
      "0: 640x640 5 cars, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 1 car, 1 truck, 6.0ms\n",
      "0: 640x640 1 person, 1 car, 1 truck, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 1 truck, 6.0ms\n",
      "0: 640x640 4 cars, 1 truck, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 1 fire hydrant, 9.0ms\n",
      "0: 640x640 4 cars, 1 fire hydrant, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 7.7ms\n",
      "0: 640x640 2 cars, 7.7ms\n",
      "Speed: 0.0ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 0.0ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 7.0ms\n",
      "0: 640x640 3 cars, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 train, 9.5ms\n",
      "0: 640x640 1 train, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 9.1ms\n",
      "0: 640x640 6 cars, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 1.0ms preprocess, 11.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 11.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 10.5ms\n",
      "0: 640x640 3 cars, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 11.9ms\n",
      "0: 640x640 1 car, 11.9ms\n",
      "Speed: 1.0ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 12.7ms\n",
      "0: 640x640 3 cars, 12.7ms\n",
      "Speed: 1.0ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 13.1ms\n",
      "0: 640x640 1 car, 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "def run_inference_with_args(inference_func, args):\n",
    "    def wrapper():\n",
    "        return inference_func(args)\n",
    "    return wrapper\n",
    "\n",
    "def collect_execution_times(run_inference_func, args, iterations=100):\n",
    "    execution_times = []\n",
    "    for i in range(iterations):\n",
    "        args[\"source\"] = f\"./app/assets/sample_image_{i}.jpg\"\n",
    "        wrapper_func = run_inference_with_args(run_inference_func, args)\n",
    "        result = wrapper_func()\n",
    "        execution_times.append(result[1] * 1000)\n",
    "        ultralytics_inference_time.append(result[2])\n",
    "    return execution_times\n",
    "\n",
    "args_pytorch = {\n",
    "    \"weights\": \"./app/weights/yolov9c.pt\", \n",
    "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\",\n",
    "    \"inference_type\": \"ultralytics\",\n",
    "    \"type\": \"image\",\n",
    "    \"show\": False,\n",
    "    \"conf_threshold\": 0.6, \n",
    "    \"iou_threshold\": 0.6, \n",
    "    \"device\": \"cuda:0\"\n",
    "}\n",
    "\n",
    "args_onnx = {\n",
    "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
    "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\",\n",
    "    \"inference_type\": \"ultralytics\",\n",
    "    \"type\": \"image\", \n",
    "    \"show\": False,\n",
    "    \"conf_threshold\": 0.6, \n",
    "    \"iou_threshold\": 0.6, \n",
    "    \"device\": \"cuda:0\"\n",
    "}\n",
    "\n",
    "args_onnx_runtime_model = {\n",
    "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
    "    \"source\": \"./app/assets/sample_image_0.jpg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\",\n",
    "    \"inference_type\": \"onnxruntime_model\",\n",
    "    \"type\": \"image\", \n",
    "    \"show\": False,\n",
    "    \"conf_threshold\": 0.6, \n",
    "    \"iou_threshold\": 0.6, \n",
    "    \"device\": \"cuda:0\"\n",
    "}\n",
    "\n",
    "result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_pytorch))\n",
    "# result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_onnx))\n",
    "# result_time.append(collect_execution_times(yolo_runtime_test.onnxruntime_run_image, args_onnx_runtime_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 1 bicycle, 3 cars, 3 trucks, 20.5ms\n",
      "0: 640x640 1 person, 1 bicycle, 3 cars, 3 trucks, 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 2 traffic lights, 20.0ms\n",
      "0: 640x640 5 cars, 2 traffic lights, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 6 traffic lights, 22.5ms\n",
      "0: 640x640 5 cars, 6 traffic lights, 22.5ms\n",
      "Speed: 2.5ms preprocess, 22.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 22.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 4 cars, 6 traffic lights, 26.0ms\n",
      "0: 640x640 1 person, 4 cars, 6 traffic lights, 26.0ms\n",
      "Speed: 3.5ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 3.5ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 6 traffic lights, 26.6ms\n",
      "0: 640x640 5 cars, 6 traffic lights, 26.6ms\n",
      "Speed: 3.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 3.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 4 cars, 1 motorcycle, 1 umbrella, 21.4ms\n",
      "0: 640x640 1 person, 4 cars, 1 motorcycle, 1 umbrella, 21.4ms\n",
      "Speed: 1.5ms preprocess, 21.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 21.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 28.9ms\n",
      "0: 640x640 3 cars, 28.9ms\n",
      "Speed: 2.5ms preprocess, 28.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 28.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 2 traffic lights, 21.1ms\n",
      "0: 640x640 1 car, 2 traffic lights, 21.1ms\n",
      "Speed: 2.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 22.8ms\n",
      "0: 640x640 6 cars, 22.8ms\n",
      "Speed: 3.0ms preprocess, 22.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 3.0ms preprocess, 22.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 27.2ms\n",
      "0: 640x640 (no detections), 27.2ms\n",
      "Speed: 2.4ms preprocess, 27.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.4ms preprocess, 27.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 22.1ms\n",
      "0: 640x640 6 cars, 22.1ms\n",
      "Speed: 2.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 1 car, 1 truck, 23.5ms\n",
      "0: 640x640 1 person, 1 car, 1 truck, 23.5ms\n",
      "Speed: 2.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 7 cars, 25.5ms\n",
      "0: 640x640 7 cars, 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 bicycle, 4 cars, 26.1ms\n",
      "0: 640x640 1 bicycle, 4 cars, 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 2 trucks, 25.5ms\n",
      "0: 640x640 2 cars, 2 trucks, 25.5ms\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 5 cars, 21.2ms\n",
      "0: 640x640 1 person, 5 cars, 21.2ms\n",
      "Speed: 2.0ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 26.1ms\n",
      "0: 640x640 3 cars, 26.1ms\n",
      "Speed: 2.5ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 24.5ms\n",
      "0: 640x640 4 cars, 24.5ms\n",
      "Speed: 2.5ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 3 persons, 2 bananas, 21.1ms\n",
      "0: 640x640 3 persons, 2 bananas, 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 8 cars, 26.1ms\n",
      "0: 640x640 8 cars, 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 21.0ms\n",
      "0: 640x640 1 car, 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 1 truck, 26.1ms\n",
      "0: 640x640 1 car, 1 truck, 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 24.1ms\n",
      "0: 640x640 1 car, 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 24.7ms\n",
      "0: 640x640 4 cars, 24.7ms\n",
      "Speed: 2.0ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 1 bus, 21.6ms\n",
      "0: 640x640 2 cars, 1 bus, 21.6ms\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 1 fire hydrant, 26.5ms\n",
      "0: 640x640 6 cars, 1 fire hydrant, 26.5ms\n",
      "Speed: 2.1ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.1ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 22.4ms\n",
      "0: 640x640 1 car, 22.4ms\n",
      "Speed: 2.0ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 1 traffic light, 22.0ms\n",
      "0: 640x640 2 cars, 1 traffic light, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 9 cars, 23.1ms\n",
      "0: 640x640 9 cars, 23.1ms\n",
      "Speed: 1.0ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 21.5ms\n",
      "0: 640x640 1 car, 21.5ms\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 27.1ms\n",
      "0: 640x640 (no detections), 27.1ms\n",
      "Speed: 1.0ms preprocess, 27.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 27.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 6 cars, 25.5ms\n",
      "0: 640x640 1 person, 6 cars, 25.5ms\n",
      "Speed: 3.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 3.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 26.6ms\n",
      "0: 640x640 4 cars, 26.6ms\n",
      "Speed: 1.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 20.6ms\n",
      "0: 640x640 2 cars, 20.6ms\n",
      "Speed: 1.0ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 23.8ms\n",
      "0: 640x640 (no detections), 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 25.3ms\n",
      "0: 640x640 1 car, 25.3ms\n",
      "Speed: 2.5ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 25.8ms\n",
      "0: 640x640 1 car, 25.8ms\n",
      "Speed: 2.0ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 25.6ms\n",
      "0: 640x640 2 cars, 25.6ms\n",
      "Speed: 2.5ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 22.1ms\n",
      "0: 640x640 (no detections), 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 21.1ms\n",
      "0: 640x640 5 cars, 21.1ms\n",
      "Speed: 2.5ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 26.3ms\n",
      "0: 640x640 1 car, 26.3ms\n",
      "Speed: 1.0ms preprocess, 26.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 26.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 26.1ms\n",
      "0: 640x640 5 cars, 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 23.1ms\n",
      "0: 640x640 1 car, 23.1ms\n",
      "Speed: 2.0ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 22.1ms\n",
      "0: 640x640 1 car, 22.1ms\n",
      "Speed: 2.5ms preprocess, 22.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 22.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 25.7ms\n",
      "0: 640x640 1 car, 25.7ms\n",
      "Speed: 2.0ms preprocess, 25.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 25.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 26.6ms\n",
      "0: 640x640 5 cars, 26.6ms\n",
      "Speed: 2.5ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 26.6ms\n",
      "0: 640x640 5 cars, 26.6ms\n",
      "Speed: 2.0ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 1 truck, 25.6ms\n",
      "0: 640x640 6 cars, 1 truck, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 25.6ms\n",
      "0: 640x640 4 cars, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 8 cars, 21.5ms\n",
      "0: 640x640 1 person, 8 cars, 21.5ms\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 22.9ms\n",
      "0: 640x640 1 car, 22.9ms\n",
      "Speed: 2.0ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 25.5ms\n",
      "0: 640x640 (no detections), 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 1 truck, 25.6ms\n",
      "0: 640x640 6 cars, 1 truck, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 26.3ms\n",
      "0: 640x640 1 car, 26.3ms\n",
      "Speed: 1.0ms preprocess, 26.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 26.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 22.3ms\n",
      "0: 640x640 (no detections), 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 26.1ms\n",
      "0: 640x640 2 cars, 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 22.6ms\n",
      "0: 640x640 (no detections), 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 persons, 21.7ms\n",
      "0: 640x640 2 persons, 21.7ms\n",
      "Speed: 1.0ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 21.6ms\n",
      "0: 640x640 (no detections), 21.6ms\n",
      "Speed: 1.0ms preprocess, 21.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 22.0ms\n",
      "0: 640x640 1 car, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 21.6ms\n",
      "0: 640x640 3 cars, 21.6ms\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 22.6ms\n",
      "0: 640x640 6 cars, 22.6ms\n",
      "Speed: 2.0ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 26.1ms\n",
      "0: 640x640 2 cars, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 21.5ms\n",
      "0: 640x640 5 cars, 21.5ms\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 25.3ms\n",
      "0: 640x640 2 cars, 25.3ms\n",
      "Speed: 2.5ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 1 car, 1 bus, 2 traffic lights, 22.0ms\n",
      "0: 640x640 1 person, 1 car, 1 bus, 2 traffic lights, 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 8 cars, 26.9ms\n",
      "0: 640x640 8 cars, 26.9ms\n",
      "Speed: 2.5ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 20.9ms\n",
      "0: 640x640 (no detections), 20.9ms\n",
      "Speed: 1.0ms preprocess, 20.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 20.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 1 truck, 21.6ms\n",
      "0: 640x640 4 cars, 1 truck, 21.6ms\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 persons, 4 cars, 26.5ms\n",
      "0: 640x640 2 persons, 4 cars, 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 9 cars, 1 stop sign, 22.0ms\n",
      "0: 640x640 9 cars, 1 stop sign, 22.0ms\n",
      "Speed: 2.5ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 1 car, 26.1ms\n",
      "0: 640x640 1 person, 1 car, 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 28.1ms\n",
      "0: 640x640 (no detections), 28.1ms\n",
      "Speed: 1.0ms preprocess, 28.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 28.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 21.1ms\n",
      "0: 640x640 5 cars, 21.1ms\n",
      "Speed: 2.0ms preprocess, 21.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 21.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 8 cars, 20.1ms\n",
      "0: 640x640 8 cars, 20.1ms\n",
      "Speed: 1.5ms preprocess, 20.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 20.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 22.0ms\n",
      "0: 640x640 1 car, 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 26.4ms\n",
      "0: 640x640 1 car, 26.4ms\n",
      "Speed: 1.0ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 7 cars, 1 stop sign, 27.3ms\n",
      "0: 640x640 7 cars, 1 stop sign, 27.3ms\n",
      "Speed: 2.0ms preprocess, 27.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 27.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 26.0ms\n",
      "0: 640x640 (no detections), 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 26.1ms\n",
      "0: 640x640 (no detections), 26.1ms\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 26.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 suitcase, 21.4ms\n",
      "0: 640x640 1 suitcase, 21.4ms\n",
      "Speed: 2.0ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 22.0ms\n",
      "0: 640x640 1 car, 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 21.7ms\n",
      "0: 640x640 3 cars, 21.7ms\n",
      "Speed: 1.0ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 persons, 1 fire hydrant, 23.5ms\n",
      "0: 640x640 2 persons, 1 fire hydrant, 23.5ms\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 23.0ms\n",
      "0: 640x640 1 car, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 21.0ms\n",
      "0: 640x640 5 cars, 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 1 truck, 28.1ms\n",
      "0: 640x640 4 cars, 1 truck, 28.1ms\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 5 cars, 25.2ms\n",
      "0: 640x640 5 cars, 25.2ms\n",
      "Speed: 2.0ms preprocess, 25.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 25.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 person, 1 car, 1 truck, 22.1ms\n",
      "0: 640x640 1 person, 1 car, 1 truck, 22.1ms\n",
      "Speed: 1.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 1 truck, 21.1ms\n",
      "0: 640x640 4 cars, 1 truck, 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 4 cars, 1 fire hydrant, 26.7ms\n",
      "0: 640x640 4 cars, 1 fire hydrant, 26.7ms\n",
      "Speed: 1.0ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 2 cars, 21.1ms\n",
      "0: 640x640 2 cars, 21.1ms\n",
      "Speed: 2.5ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.5ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 27.0ms\n",
      "0: 640x640 3 cars, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 train, 24.1ms\n",
      "0: 640x640 1 train, 24.1ms\n",
      "Speed: 1.0ms preprocess, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 6 cars, 22.5ms\n",
      "0: 640x640 6 cars, 22.5ms\n",
      "Speed: 2.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 28.0ms\n",
      "0: 640x640 (no detections), 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 26.3ms\n",
      "0: 640x640 3 cars, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 26.5ms\n",
      "0: 640x640 1 car, 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 3 cars, 21.0ms\n",
      "0: 640x640 3 cars, 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "\n",
      "0: 640x640 1 car, 21.8ms\n",
      "0: 640x640 1 car, 21.8ms\n",
      "Speed: 1.0ms preprocess, 21.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 1.0ms preprocess, 21.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "result_time.append(collect_execution_times(yolo_runtime_test.ultralytics_run_image, args_onnx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_time.append(collect_execution_times(yolo_runtime_test.onnxruntime_run_image, args_onnx_runtime_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pytorch+ultralytics time gpu (ms)</th>\n",
       "      <th>onnx​+ultralytics time gpu (ms)</th>\n",
       "      <th>onnx runtime time gpu (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>191.843874</td>\n",
       "      <td>8679.813814</td>\n",
       "      <td>8469.946979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>54.871425</td>\n",
       "      <td>68.066425</td>\n",
       "      <td>19.388084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>157.397500</td>\n",
       "      <td>8625.151200</td>\n",
       "      <td>8435.882200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>175.037400</td>\n",
       "      <td>8664.012800</td>\n",
       "      <td>8468.649050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>234.932750</td>\n",
       "      <td>8702.039480</td>\n",
       "      <td>8489.599770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>239.664490</td>\n",
       "      <td>8824.157170</td>\n",
       "      <td>8492.062290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>663.817700</td>\n",
       "      <td>9194.490300</td>\n",
       "      <td>8569.691800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pytorch+ultralytics time gpu (ms)  onnx​+ultralytics time gpu (ms)  \\\n",
       "count                         100.000000                       100.000000   \n",
       "mean                          191.843874                      8679.813814   \n",
       "std                            54.871425                        68.066425   \n",
       "min                           157.397500                      8625.151200   \n",
       "50%                           175.037400                      8664.012800   \n",
       "90%                           234.932750                      8702.039480   \n",
       "95%                           239.664490                      8824.157170   \n",
       "max                           663.817700                      9194.490300   \n",
       "\n",
       "       onnx runtime time gpu (ms)  \n",
       "count                  100.000000  \n",
       "mean                  8469.946979  \n",
       "std                     19.388084  \n",
       "min                   8435.882200  \n",
       "50%                   8468.649050  \n",
       "90%                   8489.599770  \n",
       "95%                   8492.062290  \n",
       "max                   8569.691800  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_time = np.array(result_time)\n",
    "df = pd.DataFrame(np.transpose(result_time), \n",
    "                  columns=[\"pytorch+ultralytics time gpu (ms)\",\n",
    "                           \"onnx​+ultralytics time gpu (ms)\", \n",
    "                           \"onnx runtime time gpu (ms)\"])\n",
    "df.describe(percentiles=[.9, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98.10328483581543,\n",
       " 95.79801559448242,\n",
       " 9.025812149047852,\n",
       " 11.525630950927734,\n",
       " 6.555795669555664,\n",
       " 91.56060218811035,\n",
       " 6.51097297668457,\n",
       " 7.009267807006836,\n",
       " 7.505893707275391,\n",
       " 6.084442138671875,\n",
       " 7.005929946899414,\n",
       " 6.040811538696289,\n",
       " 7.538318634033203,\n",
       " 6.535530090332031,\n",
       " 9.511470794677734,\n",
       " 7.190704345703125,\n",
       " 8.042573928833008,\n",
       " 6.435871124267578,\n",
       " 6.068706512451172,\n",
       " 5.999565124511719,\n",
       " 7.506847381591797,\n",
       " 6.509304046630859,\n",
       " 6.7005157470703125,\n",
       " 7.511377334594727,\n",
       " 6.548643112182617,\n",
       " 7.00068473815918,\n",
       " 5.504846572875977,\n",
       " 6.184816360473633,\n",
       " 6.055593490600586,\n",
       " 7.511377334594727,\n",
       " 6.999492645263672,\n",
       " 6.50477409362793,\n",
       " 7.014274597167969,\n",
       " 6.5174102783203125,\n",
       " 7.032632827758789,\n",
       " 6.917238235473633,\n",
       " 6.528139114379883,\n",
       " 10.012388229370117,\n",
       " 8.558511734008789,\n",
       " 10.091066360473633,\n",
       " 11.049747467041016,\n",
       " 11.321783065795898,\n",
       " 11.740684509277344,\n",
       " 13.48423957824707,\n",
       " 31.915903091430664,\n",
       " 26.539325714111328,\n",
       " 21.813392639160156,\n",
       " 19.559621810913086,\n",
       " 18.05400848388672,\n",
       " 24.796485900878906,\n",
       " 24.039745330810547,\n",
       " 24.54543113708496,\n",
       " 17.033815383911133,\n",
       " 21.297693252563477,\n",
       " 16.530275344848633,\n",
       " 23.918628692626953,\n",
       " 17.53067970275879,\n",
       " 17.0133113861084,\n",
       " 16.017436981201172,\n",
       " 27.051925659179688,\n",
       " 17.84038543701172,\n",
       " 21.615982055664062,\n",
       " 21.210432052612305,\n",
       " 20.04241943359375,\n",
       " 6.016254425048828,\n",
       " 6.51860237121582,\n",
       " 6.022214889526367,\n",
       " 7.027149200439453,\n",
       " 6.73365592956543,\n",
       " 5.999326705932617,\n",
       " 5.373477935791016,\n",
       " 10.592460632324219,\n",
       " 10.265111923217773,\n",
       " 10.075807571411133,\n",
       " 11.603116989135742,\n",
       " 12.899637222290039,\n",
       " 11.986494064331055,\n",
       " 12.40086555480957,\n",
       " 23.122310638427734,\n",
       " 20.046472549438477,\n",
       " 6.530284881591797,\n",
       " 6.0253143310546875,\n",
       " 6.530046463012695,\n",
       " 7.534980773925781,\n",
       " 6.409168243408203,\n",
       " 7.465124130249023,\n",
       " 6.005048751831055,\n",
       " 6.005048751831055,\n",
       " 6.023645401000977,\n",
       " 6.017208099365234,\n",
       " 9.022712707519531,\n",
       " 7.714986801147461,\n",
       " 7.0056915283203125,\n",
       " 9.525537490844727,\n",
       " 9.063005447387695,\n",
       " 11.092185974121094,\n",
       " 10.532617568969727,\n",
       " 11.857748031616211,\n",
       " 12.674093246459961,\n",
       " 13.14854621887207,\n",
       " 20.549535751342773,\n",
       " 20.025253295898438,\n",
       " 22.536277770996094,\n",
       " 26.043415069580078,\n",
       " 26.581525802612305,\n",
       " 21.384239196777344,\n",
       " 28.905153274536133,\n",
       " 21.075725555419922,\n",
       " 22.797346115112305,\n",
       " 27.227163314819336,\n",
       " 22.05514907836914,\n",
       " 23.450851440429688,\n",
       " 25.465726852416992,\n",
       " 26.083946228027344,\n",
       " 25.54631233215332,\n",
       " 21.170377731323242,\n",
       " 26.0622501373291,\n",
       " 24.541139602661133,\n",
       " 21.051406860351562,\n",
       " 26.076555252075195,\n",
       " 21.046876907348633,\n",
       " 26.079893112182617,\n",
       " 24.111032485961914,\n",
       " 24.698257446289062,\n",
       " 21.595001220703125,\n",
       " 26.499271392822266,\n",
       " 22.369384765625,\n",
       " 22.011280059814453,\n",
       " 23.117542266845703,\n",
       " 21.544694900512695,\n",
       " 27.050256729125977,\n",
       " 25.470495223999023,\n",
       " 26.61871910095215,\n",
       " 20.6301212310791,\n",
       " 23.755311965942383,\n",
       " 25.341272354125977,\n",
       " 25.75230598449707,\n",
       " 25.564193725585938,\n",
       " 22.116899490356445,\n",
       " 21.08287811279297,\n",
       " 26.322603225708008,\n",
       " 26.118755340576172,\n",
       " 23.05436134338379,\n",
       " 22.05657958984375,\n",
       " 25.69723129272461,\n",
       " 26.637792587280273,\n",
       " 26.55339241027832,\n",
       " 25.59828758239746,\n",
       " 25.567293167114258,\n",
       " 21.526575088500977,\n",
       " 22.907495498657227,\n",
       " 25.531291961669922,\n",
       " 25.602340698242188,\n",
       " 26.319503784179688,\n",
       " 22.336244583129883,\n",
       " 26.057004928588867,\n",
       " 22.55535125732422,\n",
       " 21.724224090576172,\n",
       " 21.58498764038086,\n",
       " 22.046804428100586,\n",
       " 21.561384201049805,\n",
       " 22.58133888244629,\n",
       " 26.07440948486328,\n",
       " 21.53778076171875,\n",
       " 25.318384170532227,\n",
       " 22.048473358154297,\n",
       " 26.91650390625,\n",
       " 20.9348201751709,\n",
       " 21.565914154052734,\n",
       " 26.529788970947266,\n",
       " 22.047758102416992,\n",
       " 26.07893943786621,\n",
       " 28.12361717224121,\n",
       " 21.126508712768555,\n",
       " 20.05457878112793,\n",
       " 22.043228149414062,\n",
       " 26.35335922241211,\n",
       " 27.33778953552246,\n",
       " 26.04842185974121,\n",
       " 26.076793670654297,\n",
       " 21.44622802734375,\n",
       " 22.011280059814453,\n",
       " 21.74091339111328,\n",
       " 23.540735244750977,\n",
       " 23.012876510620117,\n",
       " 21.011829376220703,\n",
       " 28.10811996459961,\n",
       " 25.206327438354492,\n",
       " 22.077322006225586,\n",
       " 21.05402946472168,\n",
       " 26.678800582885742,\n",
       " 21.06785774230957,\n",
       " 26.979923248291016,\n",
       " 24.104833602905273,\n",
       " 22.516965866088867,\n",
       " 28.04255485534668,\n",
       " 26.315689086914062,\n",
       " 26.484012603759766,\n",
       " 21.04949951171875,\n",
       " 21.767139434814453,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultralytics_inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pytorch+ultralytics built-in profiler time gpu (ms)</th>\n",
       "      <th>onnx+ultralytics built-in profiler time gpu (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.620884</td>\n",
       "      <td>23.954599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.678415</td>\n",
       "      <td>2.362970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.373478</td>\n",
       "      <td>20.025253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.300543</td>\n",
       "      <td>23.648024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>23.201942</td>\n",
       "      <td>26.641893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>26.564956</td>\n",
       "      <td>27.232695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.103285</td>\n",
       "      <td>28.905153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pytorch+ultralytics built-in profiler time gpu (ms)  \\\n",
       "count                                         100.000000     \n",
       "mean                                           13.620884     \n",
       "std                                            15.678415     \n",
       "min                                             5.373478     \n",
       "50%                                             8.300543     \n",
       "90%                                            23.201942     \n",
       "95%                                            26.564956     \n",
       "max                                            98.103285     \n",
       "\n",
       "       onnx+ultralytics built-in profiler time gpu (ms)  \n",
       "count                                        100.000000  \n",
       "mean                                          23.954599  \n",
       "std                                            2.362970  \n",
       "min                                           20.025253  \n",
       "50%                                           23.648024  \n",
       "90%                                           26.641893  \n",
       "95%                                           27.232695  \n",
       "max                                           28.905153  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_list_into_arrays(input_list):\n",
    "    list1 = input_list[:100]\n",
    "    list2 = input_list[100:200]\n",
    "    \n",
    "    return list1, list2\n",
    "\n",
    "array1, array2= split_list_into_arrays(ultralytics_inference_time)\n",
    "infer_timer_list = [array1, array2]\n",
    "\n",
    "infer_timer_list = np.array(infer_timer_list)\n",
    "df_infer = pd.DataFrame(np.transpose(infer_timer_list), columns=[\"pytorch+ultralytics built-in profiler time gpu (ms)\", \"onnx+ultralytics built-in profiler time gpu (ms)\"])\n",
    "df_infer.describe(percentiles=[.9, .95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save GPU result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./app/saved_pkl/gpu_df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./app/saved_pkl/gpu_infer_df.pkl', 'wb') as f:\n",
    "    pickle.dump(df_infer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

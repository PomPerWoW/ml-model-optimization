{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timer import Timer\n",
    "from app.util.util import DotDict\n",
    "from main import yolo_run_image, yolo_run_video, inference_on_image, inference_on_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pytorch_image = DotDict({\n",
    "    \"weights\": \"./app/weights/yolov9c.pt\", \n",
    "    \"source\": \"./app/assets/sample_image.jpeg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\", \n",
    "    \"type\": \"image\", \n",
    "    \"show\": False, \n",
    "    \"score_threshold\": 0.1, \n",
    "    \"conf_threshold\": 0.4, \n",
    "    \"iou_threshold\": 0.4, \n",
    "    \"device\": \"cpu\"\n",
    "})\n",
    "\n",
    "args_pytorch_video = DotDict({\n",
    "    \"weights\": \"./app/weights/yolov9c.pt\", \n",
    "    \"source\": \"./app/assets/sample_video_2.mp4\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\", \n",
    "    \"type\": \"video\", \n",
    "    \"show\": False, \n",
    "    \"score_threshold\": 0.1, \n",
    "    \"conf_threshold\": 0.4, \n",
    "    \"iou_threshold\": 0.4, \n",
    "    \"device\": \"cpu\"\n",
    "})\n",
    "\n",
    "args_onnx_image = DotDict({\n",
    "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
    "    \"source\": \"./app/assets/sample_image.jpeg\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\", \n",
    "    \"type\": \"image\", \n",
    "    \"show\": False, \n",
    "    \"score_threshold\": 0.1, \n",
    "    \"conf_threshold\": 0.4, \n",
    "    \"iou_threshold\": 0.4, \n",
    "    \"device\": \"cpu\"\n",
    "})\n",
    "\n",
    "args_onnx_video = DotDict({\n",
    "    \"weights\": \"./app/weights/yolov9c.onnx\", \n",
    "    \"source\": \"./app/assets/sample_video_2.mp4\", \n",
    "    \"classes\": \"./app/weights/metadata.yaml\", \n",
    "    \"type\": \"video\", \n",
    "    \"show\": False, \n",
    "    \"score_threshold\": 0.1, \n",
    "    \"conf_threshold\": 0.4, \n",
    "    \"iou_threshold\": 0.4, \n",
    "    \"device\": \"cpu\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_pytorch_image():\n",
    "    result = yolo_run_image(args_pytorch_image)\n",
    "    return result\n",
    "\n",
    "def run_inference_pytorch_video():\n",
    "    result = yolo_run_video(args_pytorch_video)\n",
    "    return result\n",
    "\n",
    "def run_inference_onnx_image():\n",
    "    result = yolo_run_image(args_onnx_image)\n",
    "    return result\n",
    "\n",
    "def run_inference_onnx_runtime_image():\n",
    "    result = inference_on_image(args_onnx_image)\n",
    "    return result\n",
    "\n",
    "def run_inference_onnx_runtime_video():\n",
    "    result = inference_on_video(args_onnx_video)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initialize Model\n",
      "[INFO] Inference Image\n",
      "\n",
      "0: 448x640 1 person, 1 bicycle, 6 cars, 3 trucks, 140.5ms\n",
      "Speed: 2.0ms preprocess, 140.5ms inference, 461.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Class: car, Confidence: 0.93, Box: [558, 206, 808, 359]\n",
      "Class: car, Confidence: 0.92, Box: [286, 210, 458, 352]\n",
      "Class: car, Confidence: 0.91, Box: [465, 217, 596, 339]\n",
      "Class: person, Confidence: 0.87, Box: [159, 143, 301, 403]\n",
      "Class: truck, Confidence: 0.87, Box: [103, 90, 255, 316]\n",
      "Class: truck, Confidence: 0.78, Box: [722, 170, 871, 346]\n",
      "Class: truck, Confidence: 0.75, Box: [0, 154, 94, 354]\n",
      "Class: bicycle, Confidence: 0.65, Box: [210, 321, 266, 443]\n",
      "Class: car, Confidence: 0.52, Box: [78, 212, 113, 300]\n",
      "Class: car, Confidence: 0.36, Box: [420, 226, 474, 319]\n",
      "Class: car, Confidence: 0.30, Box: [420, 227, 464, 278]\n",
      "Elapsed time: 2.0982 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.098229100000026"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_inference_pytorch_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initialize Model\n",
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "[INFO] Inference Image\n",
      "Loading app\\weights\\yolov9c.onnx for ONNX Runtime inference...\n",
      "\n",
      "0: 640x640 1 person, 1 bicycle, 6 cars, 3 trucks, 153.2ms\n",
      "Speed: 11.1ms preprocess, 153.2ms inference, 645.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class: car, Confidence: 0.93, Box: [558, 206, 808, 359]\n",
      "Class: car, Confidence: 0.92, Box: [286, 210, 458, 352]\n",
      "Class: car, Confidence: 0.91, Box: [465, 217, 596, 339]\n",
      "Class: person, Confidence: 0.87, Box: [159, 143, 301, 403]\n",
      "Class: truck, Confidence: 0.87, Box: [103, 89, 255, 316]\n",
      "Class: truck, Confidence: 0.79, Box: [722, 170, 871, 346]\n",
      "Class: truck, Confidence: 0.75, Box: [0, 154, 94, 354]\n",
      "Class: bicycle, Confidence: 0.65, Box: [210, 321, 266, 443]\n",
      "Class: car, Confidence: 0.53, Box: [78, 212, 113, 300]\n",
      "Class: car, Confidence: 0.36, Box: [420, 226, 474, 319]\n",
      "Class: car, Confidence: 0.30, Box: [420, 227, 464, 278]\n",
      "Elapsed time: 2.3961 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.396146700000031"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_inference_onnx_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Intialize Model\n",
      "[INFO] Inference Image\n",
      "Detected car with confidence 0.92: [556 206 810 359]\n",
      "Detected car with confidence 0.92: [463 217 595 338]\n",
      "Detected car with confidence 0.91: [286 210 459 351]\n",
      "Detected person with confidence 0.90: [159 143 299 403]\n",
      "Detected truck with confidence 0.84: [102  89 257 314]\n",
      "Detected bicycle with confidence 0.72: [209 322 269 441]\n",
      "Detected truck with confidence 0.68: [  0 154  93 354]\n",
      "Elapsed time: 0.1316 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13161179999951855"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_inference_onnx_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_times = []\n",
    "for i in range(10):\n",
    "    execution_time = run_inference_pytorch_image()\n",
    "    execution_times.append(execution_time)\n",
    "\n",
    "average_time = sum(execution_times) / len(execution_times)\n",
    "print(f\"\\nAverage execution time: {average_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms\n",
    "df = pd.DataFrame(execution_times, columns=[\"time (second)\"])\n",
    "print(df)\n",
    "df.describe(percentiles=[.9, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(execution_times, columns=[\"time (second)\"])\n",
    "print(df)\n",
    "df.describe(percentiles=[.9, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(execution_times, columns=[\"time (second)\"])\n",
    "print(df)\n",
    "df.describe(percentiles=[.9, .95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(execution_times, columns=[\"time (second)\"])\n",
    "print(df)\n",
    "df.describe(percentiles=[.9, .95])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
